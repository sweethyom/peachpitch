import { useEffect, useRef, useState } from "react";
import OpenViduVideoComponent from "./OvVideo";
import { StreamManager } from "openvidu-browser";
import { FaceDetector, FilesetResolver, Detection } from "@mediapipe/tasks-vision";
import Mask from "@/components/modal/MaskComponent";

// import { SelfieSegmentation } from "@mediapipe/selfie_segmentation";

type UserVideoComponentProps = {
    streamManager: StreamManager | null;
};

function UserVideoComponent({ streamManager }: UserVideoComponentProps) {
    const videoRef = useRef<HTMLVideoElement | null>(null);
    const canvasRef = useRef<HTMLCanvasElement | null>(null);
    const faceDetectorRef = useRef<FaceDetector | null>(null);
    const [detectedFaces, setDetectedFaces] = useState<{ x: number; y: number; width: number; height: number }[]>([]);

    useEffect(() => {
        if (!streamManager) return;

        const videoElement = document.createElement("video");
        videoElement.autoplay = true;
        videoElement.playsInline = true;

        streamManager.addVideoElement(videoElement);

        videoRef.current = videoElement;

        // ‚úÖ ÏñºÍµ¥ Í∞êÏßÄ Î™®Îç∏ Ï¥àÍ∏∞Ìôî
        const initializeFaceDetector = async () => {
            try {
                const vision = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
                );
                const detector = await FaceDetector.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath:
                            "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite",
                        delegate: "GPU",
                    },
                    runningMode: "VIDEO",
                });
                faceDetectorRef.current = detector;
                console.log("‚úÖ Face Detector Ï¥àÍ∏∞Ìôî ÏôÑÎ£å");
                requestAnimationFrame(processFrame);
            } catch (error) {
                console.error("üö® Face Detector Ï¥àÍ∏∞Ìôî Ïò§Î•ò:", error);
            }
        };

        initializeFaceDetector();

        return () => {
            faceDetectorRef.current = null;
        };
    }, [streamManager]);

    // ‚úÖ ÏñºÍµ¥ Í∞êÏßÄ Ïã§Ìñâ
    const processFrame = async () => {
        if (!videoRef.current || !faceDetectorRef.current) return;
        const video = videoRef.current;

        if (video.readyState < 2) {
            requestAnimationFrame(processFrame);
            return;
        }

        // ÏñºÍµ¥ Í∞êÏßÄ
        const detections: Detection[] = faceDetectorRef.current.detectForVideo(video, performance.now()).detections;
        const faces = detections
            .map((detection) => {
                if (!detection.boundingBox) return null;

                const { originX, originY, width, height } = detection.boundingBox;

                // üö® ROI ÌÅ¨Í∏∞ Í≤ÄÏ¶ù (ÎÑàÎ¨¥ ÏûëÏúºÎ©¥ Í∞êÏßÄ Î¨¥Ïãú)
                if (width <= 0 || height <= 0) return null;

                return {
                    x: originX + width / 7,
                    y: originY + height / 8,
                    width: Math.max(width * 2.1, 50), // ÏµúÏÜå ÌÅ¨Í∏∞ 50px Ïù¥ÏÉÅ
                    height: Math.max(height * 2.1, 50),
                };
            })
            .filter((face): face is { x: number; y: number; width: number; height: number } => face !== null);

        setDetectedFaces(faces);

        requestAnimationFrame(processFrame);
    };

    return (
        <div style={{ position: "relative", width: "500px", height: "460px" }}>
            <div
                className="streamcomponent"
                style={{
                    width: "500px",
                    height: "460px",
                    borderRadius: "10px",
                    border: "2px solid #ccc",
                    overflow: "hidden",
                    display: "flex",
                    justifyContent: "center",
                    alignItems: "center",
                    position: "relative",
                }}
            >
                <OpenViduVideoComponent streamManager={streamManager} />
                <canvas ref={canvasRef} style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }} />
            </div>

            {/* Í∞êÏßÄÎêú ÏñºÍµ¥ ÏúÑÏóê CatFace Ï∂îÍ∞Ä */}
            {detectedFaces.map((face, index) => (
                <Mask key={index} x={face.x} y={face.y} width={face.width} height={face.height} />
            ))}
        </div>
    );
}

export default UserVideoComponent;
